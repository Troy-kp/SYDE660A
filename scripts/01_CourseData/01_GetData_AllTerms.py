#!/usr/bin/python3
# coding=utf-8
# author troy

import requests
import json
import os
import time
from datetime import datetime

# --- æ‚¨çš„APIå¯†é’¥ ---
api_key = "82EE1A91C80C48168A2B7156862DE865"
headers = {'x-api-key': api_key}

# --- é…ç½®è®¾ç½® ---
class Config:
    # =================================================================
    # æ•°æ®è·å–èŒƒå›´é…ç½® (ä¸‰ç§æ¨¡å¼)
    # =================================================================
    
    # æ¨¡å¼1: æ¨èé…ç½® (åŸºäºå®é™…è¯¾ç¨‹è¡¨éªŒè¯çš„æœ€ä¼˜èŒƒå›´)
    MODE_RECOMMENDED = {
        'enabled': True,
        'start_year': 2021,  # åŸºäºæ™ºèƒ½æ¢ç´¢ï¼š100%æ•°æ®æœ‰æ•ˆæ€§
        'end_year': 2025,    # æœ€æ–°æœ‰æ•ˆå­¦æœŸ
        'description': 'æ¨èé…ç½®ï¼šåŸºäºå®é™…è¯¾ç¨‹è¡¨éªŒè¯çš„æœ€ä½³æ•°æ®èŒƒå›´'
    }
    
    # æ¨¡å¼2: è‡ªå®šä¹‰å¹´ä»½èŒƒå›´ (å¯éšæ—¶è°ƒæ•´)
    MODE_CUSTOM = {
        'enabled': False,
        'start_year': 2020,  # ğŸ”§ å¯è°ƒæ•´ï¼šæœ€æ—©æœ‰æ•ˆå¹´ä»½
        'end_year': 2025,    # ğŸ”§ å¯è°ƒæ•´ï¼šæœ€æ–°æœ‰æ•ˆå¹´ä»½
        'description': 'å®Œæ•´æœ‰æ•ˆèŒƒå›´ï¼šåŒ…å«æ‰€æœ‰éªŒè¯æœ‰æ•ˆçš„å­¦æœŸ'
    }
    
    # æ¨¡å¼3: å®Œæ•´å†å²æ•°æ® (1956-2029ï¼Œæ•°æ®é‡å·¨å¤§)
    MODE_ALL_HISTORICAL = {
        'enabled': False,
        'description': 'å®Œæ•´å†å²ï¼šè·å–æ‰€æœ‰74å¹´æ•°æ®ï¼ˆéœ€è¦å¾ˆé•¿æ—¶é—´ï¼‰'
    }
    
    # æ¨¡å¼4: ä»…æœ€æ–°æ•°æ® (å¿«é€Ÿæµ‹è¯•ç”¨)
    MODE_RECENT_ONLY = {
        'enabled': False,
        'start_year': 2025,
        'end_year': 2025,
        'description': 'ä»…æœ€æ–°ï¼šåªè·å–2025å¹´æ•°æ®è¿›è¡Œå¿«é€Ÿæµ‹è¯•'
    }
    
    # æ¨¡å¼5: éªŒè¯æœ‰æ•ˆçš„å®Œæ•´èŒƒå›´ (2020-2025ï¼ŒåŸºäºæ™ºèƒ½æ¢ç´¢ç»“æœ)
    MODE_VERIFIED_COMPLETE = {
        'enabled': False,
        'start_year': 2020,  # æœ€æ—©æœ‰éƒ¨åˆ†æœ‰æ•ˆæ•°æ®çš„å¹´ä»½
        'end_year': 2025,    # æœ€æ–°æœ‰æ•ˆå¹´ä»½
        'description': 'å®Œæ•´éªŒè¯ï¼šåŒ…å«æ‰€æœ‰ç»è¿‡è¯¾ç¨‹è¡¨éªŒè¯çš„æœ‰æ•ˆå­¦æœŸ (17ä¸ªå­¦æœŸ)'
    }
    
    # =================================================================
    # è¯¾ç¨‹ç±»å‹è¿‡æ»¤
    # =================================================================
    # æ¨èè®¾ç½®ï¼šåŒ…å«æ‰€æœ‰è¯¾ç¨‹ç±»å‹ï¼Œæä¾›æœ€å¤§çµæ´»æ€§
    # ä¼˜åŠ¿ï¼š
    # 1. æ”¯æŒç ”ç©¶ç”Ÿé€‰æ‹©é«˜çº§æœ¬ç§‘è¯¾ç¨‹
    # 2. æœªæ¥å¯æ‰©å±•åˆ°æœ¬ç§‘ç”Ÿæ¨èç³»ç»Ÿ
    # 3. å®Œæ•´çš„å…ˆä¿®è¯¾ç¨‹ä¾èµ–å…³ç³»ç½‘ç»œ
    # 4. è·¨å±‚æ¬¡çš„å­¦ä¹ è·¯å¾„è§„åˆ’
    INCLUDE_GRADUATE_ONLY = False  # True: åªè·å–ç ”ç©¶ç”Ÿè¯¾ç¨‹, False: è·å–æ‰€æœ‰è¯¾ç¨‹
    INCLUDE_UNDERGRADUATE = True   # æ˜¯å¦åŒ…å«æœ¬ç§‘ç”Ÿè¯¾ç¨‹
    
    # è¾“å‡ºç›®å½•
    OUTPUT_BASE_DIR = "API_course_data_comprehensive"
    FILTERED_OUTPUT_BASE_DIR = "API_course_data_filtered"
    GRADUATE_DIR = "graduate_courses"
    ALL_COURSES_DIR = "all_courses"
    SCHEDULE_DIR = "API_schedule_data_comprehensive"
    
    # æ¨èï¼šä¸ºäº†æ›´å¥½çš„æ•°æ®ç»„ç»‡ï¼Œå»ºè®®ä½¿ç”¨æ–°çš„ç›®å½•ç»“æ„
    # OUTPUT_BASE_DIR = "../course_data_complete"  # æ–°çš„å®Œæ•´æ•°æ®é›†ç›®å½•
    
    # æ€§èƒ½è®¾ç½®
    REQUEST_DELAY = 0.3  # è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
    MAX_RETRIES = 3      # æœ€å¤§é‡è¯•æ¬¡æ•°
    BATCH_SIZE = 10      # æ‰¹å¤„ç†å¤§å°

def setup_directories():
    """åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆåŸå§‹ã€è¿‡æ»¤åã€è¯¾è¡¨ï¼‰"""
    # åŸå§‹è¯¾ç¨‹æ•°æ®å­ç›®å½•ï¼ˆæŒ‰ç…§æ˜¯å¦ä»…ç ”ç©¶ç”Ÿï¼‰
    subdir = Config.GRADUATE_DIR if Config.INCLUDE_GRADUATE_ONLY else Config.ALL_COURSES_DIR

    course_raw_dir = os.path.join(Config.OUTPUT_BASE_DIR, subdir)
    course_filtered_dir = os.path.join(Config.FILTERED_OUTPUT_BASE_DIR, subdir)
    schedule_data_dir = Config.SCHEDULE_DIR

    for directory in [course_raw_dir, course_filtered_dir, schedule_data_dir]:
        if not os.path.exists(directory):
            os.makedirs(directory)
            print(f"âœ… åˆ›å»ºç›®å½•: {directory}")

    return course_raw_dir, course_filtered_dir, schedule_data_dir

def get_all_subjects():
    """è·å–æ‰€æœ‰ä¸“ä¸šåˆ—è¡¨"""
    subjects_url = "https://openapi.data.uwaterloo.ca/v3/Subjects"
    print("\nğŸ” æ­£åœ¨è·å–æ‰€æœ‰ä¸“ä¸šä»£ç åˆ—è¡¨...")
    
    try:
        subjects_response = requests.get(subjects_url, headers=headers)
        subjects_response.raise_for_status()
        all_subjects = subjects_response.json()
        print(f"âœ… æˆåŠŸè·å–åˆ° {len(all_subjects)} ä¸ªä¸“ä¸š")
        return all_subjects
    except Exception as e:
        print(f"âŒ è·å–ä¸“ä¸šåˆ—è¡¨å¤±è´¥: {e}")
        return None

def get_all_terms():
    """è·å–æ‰€æœ‰å¯ç”¨å­¦æœŸ"""
    terms_url = "https://openapi.data.uwaterloo.ca/v3/Terms"
    print("\nğŸ” æ­£åœ¨è·å–æ‰€æœ‰å­¦æœŸåˆ—è¡¨...")
    
    try:
        terms_response = requests.get(terms_url, headers=headers)
        terms_response.raise_for_status()
        all_terms = terms_response.json()
        print(f"âœ… æˆåŠŸè·å–å­¦æœŸåˆ—è¡¨ï¼Œæ€»å…± {len(all_terms)} ä¸ªå­¦æœŸ")
        return all_terms
    except Exception as e:
        print(f"âŒ è·å–å­¦æœŸåˆ—è¡¨å¤±è´¥: {e}")
        return None

def filter_terms(all_terms):
    """æ ¹æ®é…ç½®è¿‡æ»¤å­¦æœŸ"""
    # ç¡®å®šå¯ç”¨çš„æ¨¡å¼
    active_mode = None
    mode_name = ""
    
    if Config.MODE_RECOMMENDED['enabled']:
        active_mode = Config.MODE_RECOMMENDED
        mode_name = "æ¨èæ¨¡å¼"
    elif Config.MODE_CUSTOM['enabled']:
        active_mode = Config.MODE_CUSTOM
        mode_name = "è‡ªå®šä¹‰æ¨¡å¼"
    elif Config.MODE_ALL_HISTORICAL['enabled']:
        print(f"ğŸ“… {Config.MODE_ALL_HISTORICAL['description']} ({len(all_terms)} ä¸ªå­¦æœŸ)")
        return all_terms
    elif Config.MODE_RECENT_ONLY['enabled']:
        active_mode = Config.MODE_RECENT_ONLY
        mode_name = "æœ€æ–°æ•°æ®æ¨¡å¼"
    elif Config.MODE_VERIFIED_COMPLETE['enabled']:
        active_mode = Config.MODE_VERIFIED_COMPLETE
        mode_name = "å®Œæ•´éªŒè¯æ¨¡å¼"
    else:
        # é»˜è®¤ä½¿ç”¨æ¨èæ¨¡å¼
        active_mode = Config.MODE_RECOMMENDED
        mode_name = "é»˜è®¤æ¨èæ¨¡å¼"
        print("âš ï¸  æ²¡æœ‰å¯ç”¨ä»»ä½•æ¨¡å¼ï¼Œä½¿ç”¨é»˜è®¤æ¨èæ¨¡å¼")
    
    # æŒ‰å¹´ä»½èŒƒå›´è¿‡æ»¤
    filtered_terms = []
    start_year = active_mode['start_year']
    end_year = active_mode['end_year']
    
    for term in all_terms:
        term_name = term.get("name", "")
        try:
            year = int(term_name.split()[-1]) if term_name else 0
            if start_year <= year <= end_year:
                filtered_terms.append(term)
        except:
            continue
    
    print(f"ğŸ“… {mode_name}: {active_mode['description']}")
    print(f"   å¹´ä»½èŒƒå›´: {start_year}-{end_year} ({len(filtered_terms)} ä¸ªå­¦æœŸ)")
    return filtered_terms

def download_course_details(all_subjects, target_terms, course_raw_dir, course_filtered_dir):
    """ä¸‹è½½æ‰€æœ‰è¯¾ç¨‹è¯¦ç»†ä¿¡æ¯ï¼ŒåŒæ—¶ç”ŸæˆæŒ‰è¯¾è¡¨è¿‡æ»¤çš„æ•°æ®"""
    print(f"\nğŸ“š å¼€å§‹ä¸‹è½½è¯¾ç¨‹è¯¦ç»†ä¿¡æ¯...")
    print(f"   ä¸“ä¸šæ•°é‡: {len(all_subjects)}")
    print(f"   å­¦æœŸæ•°é‡: {len(target_terms)}")
    print(f"   é¢„è®¡è¯·æ±‚æ•°: {len(all_subjects) * len(target_terms)}")
    
    total_courses_found = 0
    successful_requests = 0
    failed_requests = 0
    
    # æ˜¾ç¤ºå­¦æœŸä¿¡æ¯
    print(f"\nğŸ“‹ ç›®æ ‡å­¦æœŸ:")
    for term in target_terms:
        print(f"   â€¢ {term.get('name', 'N/A')} (ä»£ç : {term.get('termCode', 'N/A')})")
    
    print(f"\nğŸš€ å¼€å§‹ä¸‹è½½...")
    
    for i, subject_info in enumerate(all_subjects):
        subject_code = subject_info.get("code")
        print(f"\nğŸ“– å¤„ç†ä¸“ä¸š: {subject_code} ({i + 1}/{len(all_subjects)})")

        subject_total_courses = 0
        
        for j, term in enumerate(target_terms):
            term_code = term.get("termCode")
            term_name = term.get("name")
            
            courses_url = f"https://openapi.data.uwaterloo.ca/v3/Courses/{term_code}/{subject_code}"
            
            # é‡è¯•æœºåˆ¶
            for retry in range(Config.MAX_RETRIES):
                try:
                    courses_response = requests.get(courses_url, headers=headers)
                    if courses_response.status_code == 200:
                        raw_course_data = courses_response.json()
                        
                        if raw_course_data:
                            # æ ¹æ®é…ç½®è¿‡æ»¤è¯¾ç¨‹
                            if Config.INCLUDE_GRADUATE_ONLY:
                                # åªè·å–ç ”ç©¶ç”Ÿè¯¾ç¨‹
                                filtered_courses = [course for course in raw_course_data 
                                                  if course.get("associatedAcademicCareer") == "GRD"]
                            elif Config.INCLUDE_UNDERGRADUATE:
                                # è·å–æ‰€æœ‰è¯¾ç¨‹ï¼ˆæœ¬ç§‘ + ç ”ç©¶ç”Ÿï¼‰
                                filtered_courses = raw_course_data
                            else:
                                # åªåŒ…å«ç ”ç©¶ç”Ÿè¯¾ç¨‹ï¼ˆfallbackï¼‰
                                filtered_courses = [course for course in raw_course_data 
                                                  if course.get("associatedAcademicCareer") == "GRD"]
                            
                            if filtered_courses:
                                # åŸå§‹æ•°æ®ä¿å­˜
                                raw_subject_dir = os.path.join(course_raw_dir, subject_code)
                                if not os.path.exists(raw_subject_dir):
                                    os.makedirs(raw_subject_dir)

                                raw_file_path = os.path.join(raw_subject_dir, f"{term_code}.json")
                                with open(raw_file_path, 'w', encoding='utf-8') as f:
                                    json.dump(filtered_courses, f, ensure_ascii=False, indent=2)

                                # è¯»å–è¯¾è¡¨ï¼ŒæŒ‰å®é™…å¼€è¯¾å†è¿‡æ»¤
                                schedule_ids = set()
                                schedule_path = os.path.join(Config.SCHEDULE_DIR, f"{term_code}.json")
                                if os.path.exists(schedule_path):
                                    try:
                                        with open(schedule_path, 'r', encoding='utf-8') as sf:
                                            schedule_ids = set(json.load(sf))
                                    except Exception:
                                        pass

                                filtered_by_schedule = [c for c in filtered_courses if c.get('courseId') in schedule_ids]

                                # ä¿å­˜è¿‡æ»¤åçš„æ•°æ®
                                filt_subject_dir = os.path.join(course_filtered_dir, subject_code)
                                if not os.path.exists(filt_subject_dir):
                                    os.makedirs(filt_subject_dir)

                                filt_file_path = os.path.join(filt_subject_dir, f"{term_code}.json")
                                with open(filt_file_path, 'w', encoding='utf-8') as f:
                                    json.dump(filtered_by_schedule, f, ensure_ascii=False, indent=2)

                                subject_total_courses += len(filtered_courses)
                                total_courses_found += len(filtered_courses)

                                # ç»Ÿè®¡è¾“å‡º
                                course_type = "ç ”ç©¶ç”Ÿ" if Config.INCLUDE_GRADUATE_ONLY else "å…¨éƒ¨"
                                print(f"     âœ… {term_name}: åŸå§‹ {len(filtered_courses)} æ¡, è¿‡æ»¤å {len(filtered_by_schedule)} æ¡ ({course_type}è¯¾ç¨‹)")
                        
                        successful_requests += 1
                        break  # æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                        
                    elif courses_response.status_code == 404:
                        # 404é€šå¸¸è¡¨ç¤ºè¯¥å­¦æœŸè¯¥ä¸“ä¸šæ²¡æœ‰è¯¾ç¨‹ï¼Œè¿™æ˜¯æ­£å¸¸çš„
                        break
                    else:
                        if retry == Config.MAX_RETRIES - 1:
                            print(f"     âŒ {term_name}: HTTP {courses_response.status_code}")
                            failed_requests += 1
                        else:
                            time.sleep(1)  # é‡è¯•å‰ç­‰å¾…
                        
                except Exception as e:
                    if retry == Config.MAX_RETRIES - 1:
                        print(f"     âŒ {term_name}: é”™è¯¯ - {e}")
                        failed_requests += 1
                    else:
                        time.sleep(1)  # é‡è¯•å‰ç­‰å¾…
            
            # è¯·æ±‚é—´éš”
            time.sleep(Config.REQUEST_DELAY)
        
        if subject_total_courses > 0:
            print(f"   ğŸ“Š {subject_code} æ€»è®¡: {subject_total_courses} é—¨è¯¾ç¨‹")
    
    print(f"\nğŸ“ˆ è¯¾ç¨‹è¯¦æƒ…ä¸‹è½½ç»Ÿè®¡:")
    print(f"   âœ… æˆåŠŸè¯·æ±‚: {successful_requests}")
    print(f"   âŒ å¤±è´¥è¯·æ±‚: {failed_requests}")
    print(f"   ğŸ“š æ€»è¯¾ç¨‹æ•°: {total_courses_found}")

def download_schedules(target_terms, schedule_data_dir):
    """ä¸‹è½½è¯¾ç¨‹è¡¨ä¿¡æ¯"""
    print(f"\nğŸ“… å¼€å§‹ä¸‹è½½è¯¾ç¨‹è¡¨ä¿¡æ¯...")
    
    successful_schedules = 0
    total_schedule_records = 0
    
    for term in target_terms:
        term_code = term.get("termCode")
        term_name = term.get("name")

        print(f"\nğŸ“‹ è·å– {term_name} ({term_code}) çš„è¯¾ç¨‹è¡¨...")
        schedule_url = f"https://openapi.data.uwaterloo.ca/v3/ClassSchedules/{term_code}"

        # é‡è¯•æœºåˆ¶
        for retry in range(Config.MAX_RETRIES):
            try:
                schedule_response = requests.get(schedule_url, headers=headers)
                if schedule_response.status_code == 200:
                    schedule_data = schedule_response.json()

                    if schedule_data:
                        file_path = os.path.join(schedule_data_dir, f"{term_code}.json")
                        with open(file_path, 'w', encoding='utf-8') as f:
                            json.dump(schedule_data, f, ensure_ascii=False, indent=2)
                        
                        record_count = len(schedule_data)
                        total_schedule_records += record_count
                        successful_schedules += 1
                        print(f"   âœ… ä¿å­˜äº† {record_count:,} æ¡å¼€è¯¾è®°å½•")
                    else:
                        print(f"   âš ï¸  è¯¥å­¦æœŸè¯¾ç¨‹è¡¨ä¸ºç©º")
                    break
                    
                elif schedule_response.status_code == 404:
                    print(f"   âš ï¸  è¯¥å­¦æœŸæš‚æ— è¯¾ç¨‹è¡¨æ•°æ®")
                    break
                else:
                    if retry == Config.MAX_RETRIES - 1:
                        print(f"   âŒ HTTP {schedule_response.status_code}")
                    else:
                        time.sleep(1)
                        
            except Exception as e:
                if retry == Config.MAX_RETRIES - 1:
                    print(f"   âŒ é”™è¯¯: {e}")
                else:
                    time.sleep(1)

        time.sleep(Config.REQUEST_DELAY)
    
    print(f"\nğŸ“ˆ è¯¾ç¨‹è¡¨ä¸‹è½½ç»Ÿè®¡:")
    print(f"   âœ… æˆåŠŸå­¦æœŸ: {successful_schedules}/{len(target_terms)}")
    print(f"   ğŸ“‹ æ€»è®°å½•æ•°: {total_schedule_records:,}")

def save_metadata(all_terms, target_terms, all_subjects, course_raw_dir):
    """ä¿å­˜å…ƒæ•°æ®ä¿¡æ¯"""
    metadata = {
        "download_timestamp": datetime.now().isoformat(),
        "config": {
            "mode_recommended": Config.MODE_RECOMMENDED,
            "mode_custom": Config.MODE_CUSTOM,
            "mode_all_historical": Config.MODE_ALL_HISTORICAL,
            "mode_recent_only": Config.MODE_RECENT_ONLY,
            "mode_verified_complete": Config.MODE_VERIFIED_COMPLETE,
            "graduate_only": Config.INCLUDE_GRADUATE_ONLY,
            "include_undergraduate": Config.INCLUDE_UNDERGRADUATE,
            "data_validation": "Based on schedule data verification"
        },
        "statistics": {
            "total_available_terms": len(all_terms),
            "downloaded_terms": len(target_terms),
            "total_subjects": len(all_subjects)
        },
        "terms_downloaded": [
            {
                "term_code": term.get("termCode"),
                "term_name": term.get("name")
            }
            for term in target_terms
        ],
        "subjects": [
            {
                "code": subject.get("code"),
                "name": subject.get("name", "")
            }
            for subject in all_subjects
        ]
    }
    
    metadata_file = os.path.join(course_raw_dir, "download_metadata.json")
    with open(metadata_file, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ å…ƒæ•°æ®å·²ä¿å­˜åˆ°: {metadata_file}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ“ æ»‘é“å¢å¤§å­¦è¯¾ç¨‹æ•°æ®æ‰¹é‡è·å–å·¥å…· (å…¨å­¦æœŸç‰ˆ)")
    print("=" * 80)
    
    # æ˜¾ç¤ºé…ç½®
    print("âš™ï¸  å½“å‰é…ç½®:")
    
    # æ˜¾ç¤ºå¯ç”¨çš„æ¨¡å¼
    active_modes = []
    if Config.MODE_RECOMMENDED['enabled']:
        active_modes.append(f"æ¨èæ¨¡å¼ ({Config.MODE_RECOMMENDED['start_year']}-{Config.MODE_RECOMMENDED['end_year']})")
    if Config.MODE_CUSTOM['enabled']:
        active_modes.append(f"è‡ªå®šä¹‰æ¨¡å¼ ({Config.MODE_CUSTOM['start_year']}-{Config.MODE_CUSTOM['end_year']})")
    if Config.MODE_ALL_HISTORICAL['enabled']:
        active_modes.append("å®Œæ•´å†å²æ¨¡å¼ (1956-2029)")
    if Config.MODE_RECENT_ONLY['enabled']:
        active_modes.append(f"æœ€æ–°æ•°æ®æ¨¡å¼ ({Config.MODE_RECENT_ONLY['start_year']}-{Config.MODE_RECENT_ONLY['end_year']})")
    if Config.MODE_VERIFIED_COMPLETE['enabled']:
        active_modes.append(f"å®Œæ•´éªŒè¯æ¨¡å¼ ({Config.MODE_VERIFIED_COMPLETE['start_year']}-{Config.MODE_VERIFIED_COMPLETE['end_year']})")
    
    if not active_modes:
        active_modes.append("é»˜è®¤æ¨èæ¨¡å¼ (2021-2025)")
    
    print(f"   ğŸ“… è·å–æ¨¡å¼: {', '.join(active_modes)}")
    # ç¡®å®šè¯¾ç¨‹ç±»å‹æè¿°
    if Config.INCLUDE_GRADUATE_ONLY:
        course_type_desc = "ä»…ç ”ç©¶ç”Ÿè¯¾ç¨‹"
    elif Config.INCLUDE_UNDERGRADUATE:
        course_type_desc = "æ‰€æœ‰è¯¾ç¨‹ï¼ˆæœ¬ç§‘ + ç ”ç©¶ç”Ÿï¼‰"
    else:
        course_type_desc = "ä»…ç ”ç©¶ç”Ÿè¯¾ç¨‹ï¼ˆé»˜è®¤ï¼‰"
    
    print(f"   ğŸ“ è¯¾ç¨‹ç±»å‹: {course_type_desc}")
    print(f"   ğŸ“ è¾“å‡ºç›®å½•: {Config.OUTPUT_BASE_DIR}")
    print(f"   â±ï¸  è¯·æ±‚é—´éš”: {Config.REQUEST_DELAY}ç§’")
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    course_raw_dir, course_filtered_dir, schedule_data_dir = setup_directories()
    
    # è·å–åŸºç¡€æ•°æ®
    all_subjects = get_all_subjects()
    if not all_subjects:
        print("âŒ æ— æ³•è·å–ä¸“ä¸šåˆ—è¡¨ï¼Œç¨‹åºç»ˆæ­¢")
        return
    
    all_terms = get_all_terms()
    if not all_terms:
        print("âŒ æ— æ³•è·å–å­¦æœŸåˆ—è¡¨ï¼Œç¨‹åºç»ˆæ­¢")
        return
    
    # è¿‡æ»¤å­¦æœŸ
    target_terms = filter_terms(all_terms)
    if not target_terms:
        print("âŒ æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„å­¦æœŸï¼Œç¨‹åºç»ˆæ­¢")
        return
    
    print(f"\nğŸ¯ å‡†å¤‡ä¸‹è½½:")
    print(f"   ğŸ“š ä¸“ä¸š: {len(all_subjects)} ä¸ª")
    print(f"   ğŸ“… å­¦æœŸ: {len(target_terms)} ä¸ª")
    print(f"   ğŸ”¢ æ€»è¯·æ±‚: ~{len(all_subjects) * len(target_terms)} ä¸ª")
    
    # è¯¢é—®ç”¨æˆ·ç¡®è®¤
    response = input(f"\næ˜¯å¦ç»§ç»­ä¸‹è½½ï¼Ÿ[y/N]: ").strip().lower()
    if response not in ['y', 'yes']:
        print("âŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
        return
    
    start_time = datetime.now()
    print(f"\nğŸš€ å¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    # å…ˆä¸‹è½½è¯¾ç¨‹è¡¨ï¼ˆç”¨äºåç»­è¿‡æ»¤ï¼‰
    download_schedules(target_terms, schedule_data_dir)

    # å†ä¸‹è½½è¯¾ç¨‹è¯¦æƒ…ï¼ˆä¼šæ ¹æ®è¯¾è¡¨ç”Ÿæˆè¿‡æ»¤æ•°æ®ï¼‰
    download_course_details(all_subjects, target_terms, course_raw_dir, course_filtered_dir)
    
    # ä¿å­˜å…ƒæ•°æ®ï¼ˆæ”¾åœ¨åŸå§‹æ•°æ®ç›®å½•ä¸‹ï¼‰
    save_metadata(all_terms, target_terms, all_subjects, course_raw_dir)
    
    end_time = datetime.now()
    duration = end_time - start_time
    
    print("\n" + "=" * 80)
    print("âœ… æ‰€æœ‰æ•°æ®ä¸‹è½½å®Œæ¯•ï¼")
    print(f"â±ï¸  æ€»è€—æ—¶: {duration}")
    print(f"ğŸ“ è¯¾ç¨‹æ•°æ®ä¿å­˜åœ¨: {course_raw_dir}")
    print(f"ğŸ“… è¯¾ç¨‹è¡¨ä¿å­˜åœ¨: {schedule_data_dir}")

if __name__ == "__main__":
    main() 